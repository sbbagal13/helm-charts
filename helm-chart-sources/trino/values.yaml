image:
  repository: docker.io/sbagal/trino 
  tag: dev
  pullPolicy: IfNotPresent
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000

ingress:
  enabled: false 
  annotations: {}
  host: ""
  tls:
    secretName: ""

ranger:
  serviceName: trino
  # Ranger URL for Policy Manager e.g. http:<ranger host/service>:<port> 
  rangerURL: http://ranger:6080
  # Solr URL for Policy Audit e.g. http://<solr url>/solr/ranger_audits
  solrURL: http://solr-dev.apps.lv-tst01.ocp.c1b/solr/ranger_audits
  policyPollIntervalMs: 30000

server:
  workers: 3
  node:
    environment: development 
    dataDir: /data/trino
    pluginDir: /usr/lib/trino/plugin
  log:
    trino:
      level: INFO
  config:
    path: /etc/trino
    http:
      port: 8080
    processForwarded: true 
    # Trino supports multiple authentication types: PASSWORD, CERTIFICATE, OAUTH2, JWT, KERBEROS
    # For more info: https://trino.io/docs/current/security/authentication-types.html
    authenticationType: "PASSWORD"
    allowInsecureOverHTTP: true
    query:
      maxMemory: "3GB"
      maxMemoryPerNode: "1GB"
      maxTotalMemory: "6GB"
      maxTotalMemoryPerNode: "2GB"
  jvm:
    maxHeapSize: "7G"
    gcMethod:
      type: "UseG1GC"
      g1:
        heapRegionSize: "32M"

initContainers: {}
  # coordinator:
  #   - name: init-coordinator
  #     image: busybox:1.28
  #     imagePullPolicy: IfNotPresent
  #     command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
  # worker:
  #   - name: init-worker
  #     image: busybox:1.28
  #     command: ['sh', '-c', 'echo The worker is running! && sleep 3600']

auth: 
  # Set username and password
  # https://trino.io/docs/current/security/password-file.html#file-format
  # passwordAuth: "username:encrypted-password-with-htpasswd"
  #  passwordAuth: |-
  #    admin:$2y$10$igRKm/V1csmTteeuSZCMRu6yvw4pVAB6EzKSWX7JkywD6lbkRb.z6
    passwordAuthType: ldap
    ldapUrl: ldap://lasdc10.fnbm.corp:389 
    ldapUserBindPattern: ${USER}@fnbm.corp
    ldapAllowInsecure: true

accessControl: {}
  # # Supported types: pvc or configmap
  # type: pvc
  # refreshPeriod: 1s
  # # Rules file is mounted to /etc/trino/access-control
  # configFile: "/access-control/rules.json"
  # # If you use pvc as the type, you have to specify the pvcName field:
  # pvcName:
  # # If you use pvc as the type, you can specify the name of the volume with the pvcVolumeName:
  # pvcVolumeName:
  # # If you use configmap as the type, you have to specify the rules field:
  # rules:
  #   rules.json: |-
  #     {
  #       "catalogs": [
  #         {
  #           "user": "admin",
  #           "catalog": "(mysql|system)",
  #           "allow": "all"
  #         },
  #         {
  #           "group": "finance|human_resources",
  #           "catalog": "postgres",
  #           "allow": true
  #         },
  #         {
  #           "catalog": "hive",
  #           "allow": "all"
  #         },
  #         {
  #           "user": "alice",
  #           "catalog": "postgresql",
  #           "allow": "read-only"
  #         },
  #         {
  #           "catalog": "system",
  #           "allow": "none"
  #         }
  #       ],
  #       "schemas": [
  #         {
  #           "user": "admin",
  #           "schema": ".*",
  #           "owner": true
  #         },
  #         {
  #           "user": "guest",
  #           "owner": false
  #         },
  #         {
  #           "catalog": "default",
  #           "schema": "default",
  #           "owner": true
  #         }
  #       ]
  #     }

# If you want to provide your own secrets resource, you can use this field:
# connectorsSecret:

connectors: 
  # Connectors configuration usually contains sensitive data (like passwords, usernames, ...)
  # so data is stored in a secret
  # mysql.properties: |-
  #   connector.name=mysql
  #   connection-url=jdbc:mysql://mysqlserver:3306
  #   connection-user=mysqluser
  #   connection-password=mysqlpassword
  # elk.properties: |-
  #   connector.name=elasticsearch
  #   elasticsearch.host=elasticsearchserver
  #   elasticsearch.port=9200
  #   elasticsearch.default-schema-name=default
  #   elasticsearch.security=PASSWORD
  #   elasticsearch.auth.user=elastiuser
  #   elasticsearch.auth.password=elasticpassword
  #   elasticsearch.tls.enabled=true
    hive.properties: |-
      connector.name=hive-hadoop2
      hive.metastore.uri=thrift://hive-metastore:9083
      hive.s3.aws-access-key=MHmvfvpGXQxERYv7jcuJ
      hive.s3.aws-secret-key=r1GDVvFebYKoczdjzLFuMZhzzOvBiCs2cOaZw/SQ
      hive.s3.endpoint=s3.openshift-storage.svc:80
      hive.s3.path-style-access=true
      hive.s3.ssl.enabled=false
      hive.metastore.thrift.impersonation.enabled=true

    sqlserverdb.properties: |-
     connector.name=sqlserver
     connection-url=jdbc:sqlserver://LASETLTST01.fnbm.corp:1433;database=ApplicationStarSchema
     connection-user=bi_test
     connection-password=icBN1nmGUku2uAICE79q

    sqldbtableaureportprocessing.properties: |-
     connector.name=sqlserver
     connection-url=jdbc:sqlserver://LASETLTST01.fnbm.corp:1433;database=TableauReportProcessing
     connection-user=bi_test
     connection-password=icBN1nmGUku2uAICE79q

    oraclecasts06.properties: |-
     connector.name=oracle
     connection-url=jdbc:oracle:thin:@ORACASTST06.fnbm.corp:1521/CASTS06
     connection-user=caps
     connection-password=ctst



schemas: {}
  # Custom schemas that will be mounted in /etc/trino/schemas
  # testschema.json: |-
  #   {
  #     "tableName": "testtable",
  #     "schemaName": "testschema",
  #     "topicName": "testtopic",
  #     "key": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "_key",
  #                 "dataFormat": "VARCHAR",
  #                 "type": "VARCHAR",
  #                 "hidden": "false"
  #             }
  #         ]
  #     },
  #     "message": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "id",
  #                 "mapping": "id",
  #                 "type": "BIGINT"
  #             },
  #             {
  #                 "name": "test_field",
  #                 "mapping": "test_field",
  #                 "type": "VARCHAR"
  #             }
  #         ]
  #     }
  #   }

service:
  type: ClusterIP

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
